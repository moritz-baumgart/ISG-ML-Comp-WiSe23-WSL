{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcomp.data.load import load_classification_train, load_classification_test\n",
    "from mlcomp.data import preprocess\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import StackingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = load_classification_train()\n",
    "df = preprocess.drop_ft2(df)\n",
    "df = preprocess.remove_outliers(df, handling_method=preprocess.HandlingMethod.CAP_AT_MIN_MAX)\n",
    "\n",
    "X = df.drop(columns='label')\n",
    "y = df['label']\n",
    "\n",
    "# X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "#X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_hp = {  # C1\n",
    "    \"bagging_temperature\": 9.933171093235632,\n",
    "    \"depth\": 4,\n",
    "    \"l2_leaf_reg\": 5.420115711716861,\n",
    "    \"random_strength\": 0.3008985550781157,\n",
    "    \"logging_level\": \"Silent\",\n",
    "}\n",
    "cat = CatBoostClassifier(eval_metric=\"TotalF1\")\n",
    "cat.set_params(**cat_hp)\n",
    "\n",
    "hgb_hp = {  # C3\n",
    "    \"l2_regularization\": 0.04426091526172612,\n",
    "    \"learning_rate\": 0.27215534692918875,\n",
    "    \"max_bins\": 95,\n",
    "    \"max_depth\": 18,\n",
    "    \"max_leaf_nodes\": 45,\n",
    "    \"min_samples_leaf\": 3,\n",
    "}\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "hgb.set_params(**hgb_hp)\n",
    "\n",
    "\n",
    "xgb_hp = {  # C3\n",
    "    \"colsample_bylevel\": 0.6543301384218317,\n",
    "    \"colsample_bynode\": 0.9439972406076952,\n",
    "    \"colsample_bytree\": 0.7773758702787967,\n",
    "    \"gamma\": 0,\n",
    "    \"learning_rate\": 0.1827843463017609,\n",
    "    \"max_delta_step\": 4,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 0,\n",
    "    \"reg_alpha\": 0.1895331843304295,\n",
    "    \"reg_lambda\": 0.6188481066931769,\n",
    "    \"subsample\": 0.9979218768593112,\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "xgb.set_params(**xgb_hp)\n",
    "\n",
    "\n",
    "mlp_hp = {  # C1\n",
    "    \"activation\": \"logistic\",\n",
    "    \"alpha\": 0.0006796700786147267,\n",
    "    \"hidden_layer_sizes\": 108,\n",
    "    \"learning_rate\": \"adaptive\",\n",
    "    \"learning_rate_init\": 0.02899177860096097,\n",
    "    \"momentum\": 0.1650630459189415,\n",
    "    \"solver\": \"adam\",\n",
    "}\n",
    "mlp = MLPClassifier()\n",
    "mlp.set_params(**mlp_hp)\n",
    "\n",
    "estimators = [\n",
    "    (\"cat\", cat),\n",
    "    (\"hgb\", hgb),\n",
    "    (\"xgb\", xgb),\n",
    "    (\"svm\", make_pipeline(StandardScaler(), SVC())),\n",
    "    (\"stdscale_mlp\", make_pipeline(StandardScaler(), mlp)),\n",
    "    (\"lgbm\", LGBMClassifier()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, n_jobs=-1)\n",
    "\n",
    "pipe = make_pipeline(SMOTE(), clf)\n",
    "\n",
    "cross_val_score(pipe, X, y, scoring='f1_macro', cv=3).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StackingClassifier(estimators=estimators, n_jobs=-1)\n",
    "pipe.fit(X, y)\n",
    "\n",
    "test = load_classification_test()\n",
    "test = preprocess.drop_ft2(test)\n",
    "test = preprocess.remove_outliers(test, handling_method=preprocess.HandlingMethod.CAP_AT_MIN_MAX)\n",
    "#test = StandardScaler().fit_transform(test)\n",
    "\n",
    "prediction = pipe.predict(test)\n",
    "df = pd.DataFrame(prediction, columns=[\"label\"])\n",
    "df.to_csv(\"pred.csv\", index_label=\"Id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !ATTENTION!: Please see doc.md. I did a mistake using SMOTE and CV, which causes most of the validation results here to be wrong.\n",
    "\n",
    "\n",
    "#### (1) Stack(Cat-C1, HGB-C3, XGB-C3), drop2, cap outlier, smote\n",
    "- Val: 0.8683956033883564\n",
    "- Kaggle: 0.78982\n",
    "\n",
    "#### (2) Stack(Cat-C1, HGB-C3, XGB-C3, SVC), drop2, cap outlier, smote\n",
    "- Val: 0.8714865289115579\n",
    "- Kaggle: 0.79674\n",
    "\n",
    "#### (3) Stack(Cat-C1, HGB-C3, XGB-C3, (StdScale + SVC)), drop2, cap outlier, smote\n",
    "- Val: 0.8700799654038611\n",
    "- Kaggle: 0.77174\n",
    "\n",
    "#### (4) Stack(Cat-C1, HGB-C3, XGB-C3, (StdScale + SVC), (StdScale + KNN)), drop2, cap outlier, smote\n",
    "- Val: 0.8675240682428484\n",
    "- Kaggle: 0.78844\n",
    "\n",
    "#### (5) Stack(Cat-C1, HGB-C3, XGB-C3, SVC, (StdScale + MLP)), drop2, cap outlier, smote\n",
    "- Val: 0.864481808027894\n",
    "- Kaggle: 0.81036\n",
    "\n",
    "#### (6) Stack(Cat-C1, HGB-C3, XGB-C3, SVC, (StdScale + MLP-C1)), drop2, cap outlier, smote\n",
    "- Val: 0.8629149982016588\n",
    "- Kaggle: 0.79677\n",
    "\n",
    "#### (7) Stack(Cat-C1, HGB-C3, XGB-C3, (StdScale + SVC), (StdScale + MLP-C1)), drop2, cap outlier, smote\n",
    "- Val: 0.8753143683305312\n",
    "- Kaggle: 0.76787\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Scores below here are correct again\n",
    "\n",
    "#### (8) Stack(Cat-C1, HGB-C3, XGB-C3, (StdScale + SVC), (StdScale + MLP-C1), LGBM), drop2, cap outlier, smote\n",
    "- Val: 0.8018078052395957\n",
    "- Kaggle: 0.78283\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
